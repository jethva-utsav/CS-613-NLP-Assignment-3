{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "W1Bvh-Ujz6NN"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq0KI5guuNMY",
        "colab_type": "code",
        "outputId": "0b346da7-2128-4b8f-c0e7-ca9bca6eb2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiA_VLhrbpIC",
        "colab_type": "text"
      },
      "source": [
        "# Precprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bK_y2eFbEYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp = open(\"/content/gdrive/Shared drives/NLP/Assignment 3/train.txt\", 'r')\n",
        "raw_train=[]\n",
        "q=0\n",
        "while(q!=15131):\n",
        "  lst=[]\n",
        "  q=q+1\n",
        "  for line in fp:\n",
        "    line = line.strip()\n",
        "    if len(line.split())>1:\n",
        "      lst.append(line.split())\n",
        "    if line=='':\n",
        "      raw_train.append(lst)\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIYTVoS4Kack",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_test[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwfa31sVKXkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp = open(\"/content/gdrive/Shared drives/NLP/Assignment 3/test.txt\", 'r')\n",
        "raw_test=[]\n",
        "q=0\n",
        "while(q!=1869):\n",
        "  lst=[]\n",
        "  q=q+1\n",
        "  for line in fp:\n",
        "    line = line.strip()\n",
        "    if len(line.split())>1:\n",
        "      lst.append(line.split())\n",
        "    if line=='':\n",
        "      raw_test.append(lst)\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5_u2b5zbETj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = []\n",
        "train_id = []\n",
        "for tweet in raw_train:\n",
        "  train_id.append(tweet[0][1])\n",
        "  y_train.append(tweet[0][2])\n",
        "\n",
        "y_test = []\n",
        "test_id = []\n",
        "for tweet in raw_test:\n",
        "  test_id.append(tweet[0][1])\n",
        "  y_test.append(tweet[0][2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Az9PTfXbEMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68819ef0-8031-45a9-d93d-c4f10b17f08d"
      },
      "source": [
        "from collections import Counter\n",
        "train_dist = Counter(y_train)\n",
        "train_dist"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 4459, 'neutral': 5638, 'positive': 5034})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB3hHOpRbxm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "994faca6-52f0-4f1b-b75d-2e492347f174"
      },
      "source": [
        "#from collections import Counter\n",
        "test_dist = Counter(y_test)\n",
        "test_dist"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 533, 'neutral': 754, 'positive': 582})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MREpjCnLb6GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(\"y_train.txt\",'w') as f:\n",
        "#   for id1, sentiment in zip(train_id, y_train):\n",
        "#       f.write(id1+\"\\t\"+sentiment+\"\\n\")\n",
        "  \n",
        "# with open(\"y_test.txt\",'w') as f:\n",
        "#   for id1, sentiment in zip(test_id, y_test):\n",
        "#       f.write(id1+\"\\t\"+sentiment+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCqYRverKhhp",
        "colab_type": "text"
      },
      "source": [
        "Pre-processing is done using regex, since we already have words tokenized, if token matches [a-zA-Z], it is accepted else it is rejected.\n",
        "\n",
        "But URL token such as 'http', 't', and 'co', is not filtered from above regex so we use conditional regex to filter it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqNha8Xgb6CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "new_train = []\n",
        "for i in range(15131):\n",
        "  temp = []\n",
        "  for j in range(len(raw_train[i])):\n",
        "    if bool(re.match(\"^[a-zA-Z]+$\",raw_train[i][j][0])):\n",
        "      if bool(re.match(\"^(http)|(^t$)|(^co$)\",raw_train[i][j][0])):\n",
        "        continue\n",
        "      else:\n",
        "        raw_train[i][j][0] = raw_train[i][j][0].lower()\n",
        "        temp.append(raw_train[i][j])\n",
        "  new_train.append(temp[1:])\n",
        "\n",
        "X_train = []\n",
        "for tweet in new_train:\n",
        "  X_train.append(\" \".join([j[0] for j in tweet]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20h5gjgXKeBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL9ujla5b5_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "new_test = []\n",
        "for i in range(1869):\n",
        "  temp = []\n",
        "  for j in range(len(raw_test[i])):\n",
        "    if bool(re.match(\"^[a-zA-Z]+$\",raw_test[i][j][0])):\n",
        "      if bool(re.match(\"^(http)|(^t$)|(^co$)\",raw_test[i][j][0])):\n",
        "        continue\n",
        "      else:\n",
        "        raw_test[i][j][0] = raw_test[i][j][0].lower()\n",
        "        temp.append(raw_test[i][j])\n",
        "  new_test.append(temp[1:])\n",
        "\n",
        "X_test = []\n",
        "for tweet in new_test:\n",
        "  X_test.append(\" \".join([j[0] for j in tweet]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFYkzB5mcKUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(\"X_train.txt\",'w') as f:\n",
        "#   for id1, tweet in zip(train_id, final_new_train):\n",
        "#       f.write(id1+\"\\t\"+\" \".join([j[0] for j in tweet[1:-1]])+\"\\n\")\n",
        "\n",
        "# with open(\"X_test.txt\",'w') as f:\n",
        "#   for id1, tweet in zip(test_id, final_new_test):\n",
        "#       f.write(id1+\"\\t\"+\" \".join([j[0] for j in tweet[1:-1]])+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1TY3JKT9Phi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lguy-_e9QBA",
        "colab_type": "text"
      },
      "source": [
        "# CSNLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8tSx2Nd9Rnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp = open(\"/content/gdrive/Shared drives/NLP/Assignment 3/train_tweets_translated.txt\", 'r')\n",
        "\n",
        "X_train_csnli=[]\n",
        "\n",
        "tweets = []\n",
        "for line in fp:\n",
        "  if line != \"\\n\":\n",
        "    tweets.append(line[:-1])\n",
        "\n",
        "raw = []\n",
        "csnli = []\n",
        "english = []\n",
        "\n",
        "\n",
        "i = 0\n",
        "while i < len(tweets)-2:\n",
        "  raw.append(tweets[i])\n",
        "  csnli.append(tweets[i+1])\n",
        "  english.append(tweets[i+2])\n",
        "  i+=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QawJQoEM9Rji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "61e9b307-cc27-46cc-ea3a-cbb6c637456d"
      },
      "source": [
        "for i in range(5):\n",
        "  print(raw[i])\n",
        "  print(csnli[i])\n",
        "  print(english[i])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pakistan ka ghra tauq he pakistan israel ko tasleem nahein kerta isko palestine kehta he occupied\n",
            "pakistan का गहरा तौक़ है pakistan israel को तस्लीम नहीं करता इसको palestine कहते हैं occupied\n",
            "pakistan has a deep stigma pakistan does not destroy israel, it is called palestine occupied\n",
            "\n",
            "\n",
            "mulle ye mathura me nahi dikha tha jab mullo ne hindu ko iss liye mara ki vo lasse ki paise mag liye\n",
            "मुल्ले यह mathura में नहीं दिखा था जब मुल्लों ने हिन्दू को इस लिए मारा कि वह लस्सी की पैसे मग लिए\n",
            "Mullahs did not show this in mathura when the mullahs hit the Hindu for mug of lassi\n",
            "\n",
            "\n",
            "manya pradhan mantri mahoday shriman narendra modi ji pradhanmantri banne par hardik badhai tahe\n",
            "मान्य pradhan mantri महोदय shriman narendra modi जी प्रधानमंत्री बनने पर हार्दिक बधाई ताहि\n",
            "Valid pradhan mantri sir shriman narendra modi ji hearty congratulations on becoming prime minister\n",
            "\n",
            "\n",
            "krishna jcb full trend me chal rahi\n",
            "krishna jcb full trend में चल रही\n",
            "krishna jcb operates in full trend\n",
            "\n",
            "\n",
            "ravishkumarblog loksabha me janta sirf modi ko vote de rahi thi na ki kisi mp or bjp ko without\n",
            "ravishkumarblog लोकसभा में जनता सिर्फ modi को vote दे रही थी न कि किसी mp और bjp को without\n",
            "ravishkumarblog In the Lok Sabha, the public was only voting for modi and not any mp and bjp without\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Le8adi94P7O",
        "colab_type": "text"
      },
      "source": [
        "# BERT Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrFmOQcxi4MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaGc3xXL4Wh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "c0dae502-3876-4d46-f263-18be395bd159"
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "X_train_flair = [Sentence(tweet) for tweet in X_train]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EelJAKUlEvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "X_test_flair = [Sentence(tweet) for tweet in X_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwcjdBSGcMPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.embeddings import BertEmbeddings\n",
        "import numpy as np\n",
        "embedding_bert = BertEmbeddings(\"bert-base-cased\")\n",
        "\n",
        "X_train_bert = []\n",
        "for sent in X_train_flair:\n",
        "  sent_emb = np.array(embedding_bert.embed(sent)[0])\n",
        "  emb = []\n",
        "  for token in sent_emb:\n",
        "    emb.append(np.array(token.embedding.cpu()))\n",
        "  X_train_bert.append(np.array(emb))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aSKJx8Go2o0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2139deac-a5ac-4723-b6a9-9a939f6ee69e"
      },
      "source": [
        "EMBEDDINGS_SIZE = X_train_bert[0].shape[1]\n",
        "EMBEDDINGS_SIZE"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1tJt8Nwl3e-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_bert = []\n",
        "for sent in X_test_flair:\n",
        "  sent_emb = np.array(embedding_bert.embed(sent)[0])\n",
        "  emb = []\n",
        "  for token in sent_emb:\n",
        "    emb.append(np.array(token.embedding.cpu()))\n",
        "  X_test_bert.append(np.array(emb))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysF8oOypmHv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "95570f04-a50a-415e-ef45-2c14cfb0887e"
      },
      "source": [
        "MAX_SEQ_LEN_train = max([len(tweet.split()) for tweet in X_train])\n",
        "print(MAX_SEQ_LEN_train)\n",
        "\n",
        "MAX_SEQ_LEN_test = max([len(tweet.split()) for tweet in X_test])\n",
        "print(MAX_SEQ_LEN_test)\n",
        "\n",
        "MAX_SEQ_LEN = min(MAX_SEQ_LEN_train, MAX_SEQ_LEN_test)\n",
        "MAX_SEQ_LEN"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35\n",
            "31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALfhJCQB5sZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_train_bert = np.load(\"/content/gdrive/Shared drives/NLP/Assignment 3/bert_train.npy\", allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d3OLIfW52cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_test_bert = np.load(\"/content/gdrive/Shared drives/NLP/Assignment 3/bert_test.npy\", allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjVhreRqmHka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "emb_list = []\n",
        "for i in X_train_bert:\n",
        "  emb_list.append(torch.tensor(i[:31]))\n",
        "X_train_bert_padded = pad_sequence(emb_list, batch_first=True)\n",
        "\n",
        "emb_list = []\n",
        "for i in X_test_bert:\n",
        "  emb_list.append(torch.tensor(i[:MAX_SEQ_LEN]))\n",
        "X_test_bert_padded = pad_sequence(emb_list, batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYI9BuV2mYGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a7739636-fcec-4f75-f88e-853390e6763a"
      },
      "source": [
        "y_dct = {'negative':0, \"neutral\":1,\"positive\":2}\n",
        "print(y_train[:5])\n",
        "\n",
        "for i, sentiment in enumerate(y_train):\n",
        "  y_train[i] = y_dct[sentiment]\n",
        "\n",
        "import numpy as np \n",
        "y_train = np.array(y_train)\n",
        "print(y_train[:5])\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y_train.reshape(-1, 1))\n",
        "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
        "\n",
        "print(y_train[:5])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative', 'negative', 'positive', 'positive', 'positive']\n",
            "[0 0 2 2 2]\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTlnZBx-mEtk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "2676d7ae-7aac-4eef-a432-2070b93018d8"
      },
      "source": [
        "y_dct = {'negative':0, \"neutral\":1,\"positive\":2}\n",
        "print(y_test[:5])\n",
        "\n",
        "y_test_int = []\n",
        "for i, sentiment in enumerate(y_test):\n",
        "  y_test_int.append(y_dct[sentiment])\n",
        "\n",
        "import numpy as np \n",
        "y_test_int = np.array(y_test_int)\n",
        "print(y_test_int[:5])\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y_test_int.reshape(-1, 1))\n",
        "y_test= enc.transform(y_test_int.reshape(-1, 1)).toarray()\n",
        "\n",
        "print(y_test[:5])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neutral', 'neutral', 'neutral', 'negative', 'positive']\n",
            "[1 1 1 0 2]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpMCfP1mEqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "2c97052d-8744-4f2d-c98f-b5c14a012d17"
      },
      "source": [
        "!pip install keras_Self_attention\n",
        "!pip install keras_tqdm"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_Self_attention in /usr/local/lib/python3.6/dist-packages (0.42.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_Self_attention) (2.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_Self_attention) (1.17.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.3.2)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.17.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.3.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEogT77wl3bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Bidirectional\n",
        "from keras import optimizers\n",
        "from keras.layers.recurrent import LSTM\n",
        "import keras\n",
        "from keras.layers import Dropout\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from keras_tqdm import TQDMNotebookCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e6IvIy7mRT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38d7b9d3-2b8d-40f5-e03a-068c6096e2e8"
      },
      "source": [
        "#------------------------------------MODELS------------------------------------------#\n",
        " \n",
        "\"\"\"#### Basic BiLSTM, no appends\n",
        "**MODEL 0.0**:\n",
        "*   BERT\n",
        "*   2 LSTM layer\n",
        "*   4 dense\n",
        "*   2 dense\n",
        "\"\"\"\n",
        "\n",
        "model_Bi_LSTM_1 = Sequential()\n",
        "model_Bi_LSTM_1.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), \n",
        "                                  input_shape=(31, 3072), \n",
        "                                  merge_mode='concat'))\n",
        "model_Bi_LSTM_1.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat'))\n",
        "model_Bi_LSTM_1.add(Dense(5, activation='softmax'))\n",
        "model_Bi_LSTM_1.add(Dense(3, activation='softmax'))\n",
        "model_Bi_LSTM_1.summary()\n",
        "model_Bi_LSTM_1.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_Bi_LSTM_1.fit(x=X_train_bert_padded.cpu().numpy(), \n",
        "                    y=y_train, \n",
        "                    validation_data=(X_test_bert_padded.cpu().numpy(), y_test),\t\n",
        "                    batch_size=31, \n",
        "                    epochs=25, \n",
        "                    shuffle=True)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 31, 20)            246640    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 20)                2480      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 105       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 18        \n",
            "=================================================================\n",
            "Total params: 249,243\n",
            "Trainable params: 249,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 15131 samples, validate on 1869 samples\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15131/15131 [==============================] - 70s 5ms/step - loss: 1.0573 - acc: 0.3953 - val_loss: 1.0495 - val_acc: 0.4082\n",
            "Epoch 2/25\n",
            "15131/15131 [==============================] - 63s 4ms/step - loss: 0.9969 - acc: 0.4885 - val_loss: 1.0185 - val_acc: 0.4510\n",
            "Epoch 3/25\n",
            "15131/15131 [==============================] - 63s 4ms/step - loss: 0.9590 - acc: 0.5120 - val_loss: 1.0028 - val_acc: 0.4575\n",
            "Epoch 4/25\n",
            "15131/15131 [==============================] - 63s 4ms/step - loss: 0.9418 - acc: 0.5247 - val_loss: 1.0171 - val_acc: 0.4532\n",
            "Epoch 5/25\n",
            "15131/15131 [==============================] - 65s 4ms/step - loss: 0.9292 - acc: 0.5333 - val_loss: 0.9995 - val_acc: 0.4933\n",
            "Epoch 6/25\n",
            "15131/15131 [==============================] - 67s 4ms/step - loss: 0.9218 - acc: 0.5417 - val_loss: 0.9924 - val_acc: 0.4971\n",
            "Epoch 7/25\n",
            "15131/15131 [==============================] - 65s 4ms/step - loss: 0.9130 - acc: 0.5512 - val_loss: 0.9937 - val_acc: 0.4912\n",
            "Epoch 8/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.9029 - acc: 0.5506 - val_loss: 0.9859 - val_acc: 0.5078\n",
            "Epoch 9/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8980 - acc: 0.5602 - val_loss: 0.9914 - val_acc: 0.4976\n",
            "Epoch 10/25\n",
            "15131/15131 [==============================] - 63s 4ms/step - loss: 0.8907 - acc: 0.5631 - val_loss: 0.9824 - val_acc: 0.5169\n",
            "Epoch 11/25\n",
            "15131/15131 [==============================] - 65s 4ms/step - loss: 0.8829 - acc: 0.5721 - val_loss: 0.9816 - val_acc: 0.5152\n",
            "Epoch 12/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8826 - acc: 0.5731 - val_loss: 0.9844 - val_acc: 0.5142\n",
            "Epoch 13/25\n",
            "15131/15131 [==============================] - 63s 4ms/step - loss: 0.8742 - acc: 0.5786 - val_loss: 0.9909 - val_acc: 0.5158\n",
            "Epoch 14/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8648 - acc: 0.5862 - val_loss: 0.9940 - val_acc: 0.5104\n",
            "Epoch 15/25\n",
            "15131/15131 [==============================] - 65s 4ms/step - loss: 0.8632 - acc: 0.5848 - val_loss: 0.9778 - val_acc: 0.5356\n",
            "Epoch 16/25\n",
            "15131/15131 [==============================] - 67s 4ms/step - loss: 0.8611 - acc: 0.5908 - val_loss: 0.9963 - val_acc: 0.5136\n",
            "Epoch 17/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8551 - acc: 0.5917 - val_loss: 0.9942 - val_acc: 0.5190\n",
            "Epoch 18/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8532 - acc: 0.5946 - val_loss: 0.9810 - val_acc: 0.5340\n",
            "Epoch 19/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8469 - acc: 0.5952 - val_loss: 0.9827 - val_acc: 0.5350\n",
            "Epoch 20/25\n",
            "15131/15131 [==============================] - 64s 4ms/step - loss: 0.8413 - acc: 0.6010 - val_loss: 0.9836 - val_acc: 0.5329\n",
            "Epoch 21/25\n",
            "15131/15131 [==============================] - 65s 4ms/step - loss: 0.8380 - acc: 0.6031 - val_loss: 0.9867 - val_acc: 0.5318\n",
            "Epoch 22/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8359 - acc: 0.6064 - val_loss: 0.9953 - val_acc: 0.5195\n",
            "Epoch 23/25\n",
            "15131/15131 [==============================] - 62s 4ms/step - loss: 0.8382 - acc: 0.6033 - val_loss: 0.9797 - val_acc: 0.5399\n",
            "Epoch 24/25\n",
            "15131/15131 [==============================] - 63s 4ms/step - loss: 0.8287 - acc: 0.6106 - val_loss: 1.0110 - val_acc: 0.5270\n",
            "Epoch 25/25\n",
            "15131/15131 [==============================] - 64s 4ms/step - loss: 0.8219 - acc: 0.6129 - val_loss: 0.9846 - val_acc: 0.5468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f300a5a6b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPddaLVF-FCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9ee5cea9-d8c5-4ccc-92ab-edcfb4b341b1"
      },
      "source": [
        "model_Bi_LSTM_1.evaluate(X_test_bert_padded.cpu().numpy(), y_test)[1]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869/1869 [==============================] - 3s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5468164795602051"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-GtIVzv95Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []          \n",
        "\n",
        "for tweet in X_test_bert_padded.cpu().numpy():\n",
        "  y_pred.append(model_Bi_LSTM_1.predict_classes(np.array([tweet])))\n",
        "\n",
        "y_pred = np.array([i[0] for i in y_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai3tUqXR-AOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "330ab28c-a8a7-44f1-fac9-7c5828713f33"
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred, target_names=target_names))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        352      133        48\n",
            "neutral         235      333       186\n",
            "positive        100      145       337\n",
            "\n",
            "\n",
            "Accuracy:  0.5468164794007491\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.66      0.58       533\n",
            "     neutral       0.55      0.44      0.49       754\n",
            "    positive       0.59      0.58      0.58       582\n",
            "\n",
            "    accuracy                           0.55      1869\n",
            "   macro avg       0.55      0.56      0.55      1869\n",
            "weighted avg       0.55      0.55      0.54      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiMge48amRP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "f54098dc-140d-4dc7-8b9a-7c74cf570165"
      },
      "source": [
        "\"\"\"\n",
        "#### Self Attention Library, no appends\n",
        "**MODEL 1.1 SelfAtt**\n",
        "\"\"\"\n",
        "\n",
        "model_Bi_LSTM_att1 = Sequential()\n",
        "model_Bi_LSTM_att1.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), input_shape=(31, 3072), merge_mode='concat'))\n",
        "model_Bi_LSTM_att1.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model_Bi_LSTM_att1.add(Bidirectional(LSTM(5, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat'))\n",
        "#model_Bi_LSTM_att1.add(Dense(5, activation='softmax'))\n",
        "model_Bi_LSTM_att1.add(Dense(3, activation='softmax'))\n",
        "model_Bi_LSTM_att1.summary()\n",
        "model_Bi_LSTM_att1.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_Bi_LSTM_att1.fit(x=X_train_bert_padded.cpu().numpy(), \n",
        "                       y=y_train, \n",
        "                       validation_data=(X_test_bert_padded.cpu().numpy(), y_test),\t\n",
        "                       batch_size=31, \n",
        "                       epochs=15, \n",
        "                       shuffle=True)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_12 (Bidirectio (None, 31, 20)            246640    \n",
            "_________________________________________________________________\n",
            "seq_self_attention_6 (SeqSel (None, 31, 20)            1345      \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 10)                1040      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 249,058\n",
            "Trainable params: 249,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15131 samples, validate on 1869 samples\n",
            "Epoch 1/15\n",
            "15131/15131 [==============================] - 94s 6ms/step - loss: 0.9922 - acc: 0.4797 - val_loss: 0.9991 - val_acc: 0.5078\n",
            "Epoch 2/15\n",
            "15131/15131 [==============================] - 84s 6ms/step - loss: 0.9206 - acc: 0.5405 - val_loss: 0.9873 - val_acc: 0.5147\n",
            "Epoch 3/15\n",
            "15131/15131 [==============================] - 82s 5ms/step - loss: 0.8983 - acc: 0.5557 - val_loss: 0.9835 - val_acc: 0.5286\n",
            "Epoch 4/15\n",
            "15131/15131 [==============================] - 84s 6ms/step - loss: 0.8822 - acc: 0.5685 - val_loss: 0.9704 - val_acc: 0.5276\n",
            "Epoch 5/15\n",
            "15131/15131 [==============================] - 83s 6ms/step - loss: 0.8738 - acc: 0.5763 - val_loss: 0.9774 - val_acc: 0.5388\n",
            "Epoch 6/15\n",
            "15131/15131 [==============================] - 86s 6ms/step - loss: 0.8570 - acc: 0.5877 - val_loss: 0.9597 - val_acc: 0.5490\n",
            "Epoch 7/15\n",
            "15131/15131 [==============================] - 82s 5ms/step - loss: 0.8491 - acc: 0.5939 - val_loss: 0.9820 - val_acc: 0.5431\n",
            "Epoch 8/15\n",
            "15131/15131 [==============================] - 83s 5ms/step - loss: 0.8403 - acc: 0.6025 - val_loss: 0.9814 - val_acc: 0.5372\n",
            "Epoch 9/15\n",
            "15131/15131 [==============================] - 85s 6ms/step - loss: 0.8346 - acc: 0.6064 - val_loss: 0.9784 - val_acc: 0.5538\n",
            "Epoch 10/15\n",
            "15131/15131 [==============================] - 82s 5ms/step - loss: 0.8238 - acc: 0.6144 - val_loss: 0.9841 - val_acc: 0.5447\n",
            "Epoch 11/15\n",
            "15131/15131 [==============================] - 82s 5ms/step - loss: 0.8131 - acc: 0.6180 - val_loss: 0.9782 - val_acc: 0.5618\n",
            "Epoch 12/15\n",
            "15131/15131 [==============================] - 84s 6ms/step - loss: 0.8121 - acc: 0.6183 - val_loss: 0.9905 - val_acc: 0.5425\n",
            "Epoch 13/15\n",
            "15131/15131 [==============================] - 84s 6ms/step - loss: 0.8029 - acc: 0.6287 - val_loss: 0.9754 - val_acc: 0.5645\n",
            "Epoch 14/15\n",
            "15131/15131 [==============================] - 82s 5ms/step - loss: 0.7969 - acc: 0.6319 - val_loss: 0.9896 - val_acc: 0.5538\n",
            "Epoch 15/15\n",
            "15131/15131 [==============================] - 83s 6ms/step - loss: 0.7919 - acc: 0.6337 - val_loss: 0.9906 - val_acc: 0.5511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f307d636278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hy1n8XTF-kq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ed5b7cd7-238c-4524-ad52-874f6287843d"
      },
      "source": [
        "model_Bi_LSTM_att1.evaluate(X_test_bert_padded.cpu().numpy(), y_test)[1]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869/1869 [==============================] - 5s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5510968433273483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkqCf65kJibo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []          \n",
        "\n",
        "for tweet in X_test_bert_padded.cpu().numpy():\n",
        "  y_pred.append(model_Bi_LSTM_att1.predict_classes(np.array([tweet])))\n",
        "\n",
        "y_pred = np.array([i[0] for i in y_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYKCWzmVJiR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c20c990d-78f4-4a67-9308-63a1fd3004bd"
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred, target_names=target_names))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        320      169        44\n",
            "neutral         209      373       172\n",
            "positive         91      154       337\n",
            "\n",
            "\n",
            "Accuracy:  0.5510968432316747\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.52      0.60      0.56       533\n",
            "     neutral       0.54      0.49      0.51       754\n",
            "    positive       0.61      0.58      0.59       582\n",
            "\n",
            "    accuracy                           0.55      1869\n",
            "   macro avg       0.55      0.56      0.55      1869\n",
            "weighted avg       0.55      0.55      0.55      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuANWnp88g4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "1d0a0666-844e-4c01-ad46-646a4a792713"
      },
      "source": [
        "from keras.layers import GRU\n",
        "model_GRU = Sequential()\n",
        "model_GRU.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), input_shape=(31, 3072), merge_mode='concat'))\n",
        "#model_GRU.add(GRU(8, dropout=0.5, recurrent_dropout=0.5, return_sequences=True))\n",
        "model_GRU.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model_GRU.add(GRU(8, dropout=0.5, recurrent_dropout=0.5, return_sequences=False))\n",
        "#model_GRU.add(Dense(8, activation='softmax'))\n",
        "model_GRU.add(Dense(3, activation='softmax'))\n",
        "model_GRU.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_GRU.fit(x=X_train_bert_padded.cpu().numpy(), \n",
        "              y=y_train, \n",
        "              validation_data=(X_test_bert_padded.cpu().numpy(), y_test),\t\n",
        "              batch_size=31, epochs=15, shuffle=True)\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15131 samples, validate on 1869 samples\n",
            "Epoch 1/15\n",
            "15131/15131 [==============================] - 84s 6ms/step - loss: 0.9971 - acc: 0.4814 - val_loss: 0.9962 - val_acc: 0.5040\n",
            "Epoch 2/15\n",
            "15131/15131 [==============================] - 76s 5ms/step - loss: 0.9262 - acc: 0.5390 - val_loss: 0.9838 - val_acc: 0.5313\n",
            "Epoch 3/15\n",
            "15131/15131 [==============================] - 77s 5ms/step - loss: 0.9070 - acc: 0.5510 - val_loss: 0.9815 - val_acc: 0.5163\n",
            "Epoch 4/15\n",
            "15131/15131 [==============================] - 75s 5ms/step - loss: 0.8928 - acc: 0.5688 - val_loss: 0.9800 - val_acc: 0.5377\n",
            "Epoch 5/15\n",
            "15131/15131 [==============================] - 80s 5ms/step - loss: 0.8771 - acc: 0.5797 - val_loss: 0.9797 - val_acc: 0.5361\n",
            "Epoch 6/15\n",
            "15131/15131 [==============================] - 75s 5ms/step - loss: 0.8739 - acc: 0.5732 - val_loss: 0.9802 - val_acc: 0.5324\n",
            "Epoch 7/15\n",
            "15131/15131 [==============================] - 77s 5ms/step - loss: 0.8677 - acc: 0.5824 - val_loss: 0.9757 - val_acc: 0.5367\n",
            "Epoch 8/15\n",
            "15131/15131 [==============================] - 76s 5ms/step - loss: 0.8597 - acc: 0.5856 - val_loss: 0.9768 - val_acc: 0.5383\n",
            "Epoch 9/15\n",
            "15131/15131 [==============================] - 78s 5ms/step - loss: 0.8577 - acc: 0.5889 - val_loss: 0.9788 - val_acc: 0.5452\n",
            "Epoch 10/15\n",
            "15131/15131 [==============================] - 75s 5ms/step - loss: 0.8493 - acc: 0.5939 - val_loss: 0.9608 - val_acc: 0.5500\n",
            "Epoch 11/15\n",
            "15131/15131 [==============================] - 76s 5ms/step - loss: 0.8475 - acc: 0.5984 - val_loss: 0.9940 - val_acc: 0.5447\n",
            "Epoch 12/15\n",
            "15131/15131 [==============================] - 74s 5ms/step - loss: 0.8468 - acc: 0.5989 - val_loss: 0.9805 - val_acc: 0.5441\n",
            "Epoch 13/15\n",
            "15131/15131 [==============================] - 76s 5ms/step - loss: 0.8329 - acc: 0.6073 - val_loss: 0.9774 - val_acc: 0.5532\n",
            "Epoch 14/15\n",
            "15131/15131 [==============================] - 74s 5ms/step - loss: 0.8344 - acc: 0.6039 - val_loss: 0.9827 - val_acc: 0.5361\n",
            "Epoch 15/15\n",
            "15131/15131 [==============================] - 75s 5ms/step - loss: 0.8287 - acc: 0.6101 - val_loss: 0.9818 - val_acc: 0.5420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30c7d6e208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFWpNQR7TedH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ee1bb864-1312-4da6-a65b-4166b96e0575"
      },
      "source": [
        "model_GRU.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_14 (Bidirectio (None, 31, 20)            246640    \n",
            "_________________________________________________________________\n",
            "seq_self_attention_7 (SeqSel (None, 31, 20)            1345      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 8)                 696       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 248,708\n",
            "Trainable params: 248,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrTQZir2J006",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1c30b51a-9cca-435f-b2b9-4654bc79da49"
      },
      "source": [
        "model_GRU.evaluate(X_test_bert_padded.cpu().numpy(), y_test)[1]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869/1869 [==============================] - 4s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5420010702823049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeDvT0asJ0o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []          \n",
        "\n",
        "for tweet in X_test_bert_padded.cpu().numpy():\n",
        "  y_pred.append(model_GRU.predict_classes(np.array([tweet])))\n",
        "\n",
        "y_pred = np.array([i[0] for i in y_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASMSJv61J6Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "b30470b7-deef-4b2b-e299-f4934d7e44ea"
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred, target_names=target_names))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        299      184        50\n",
            "neutral         195      380       179\n",
            "positive         79      169       334\n",
            "\n",
            "\n",
            "Accuracy:  0.5420010700909578\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.52      0.56      0.54       533\n",
            "     neutral       0.52      0.50      0.51       754\n",
            "    positive       0.59      0.57      0.58       582\n",
            "\n",
            "    accuracy                           0.54      1869\n",
            "   macro avg       0.54      0.55      0.55      1869\n",
            "weighted avg       0.54      0.54      0.54      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Bvh-Ujz6NN",
        "colab_type": "text"
      },
      "source": [
        "# BERT sequence classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUm4UkkBzhcs",
        "colab_type": "code",
        "outputId": "fef0497b-5139-4cfd-d0a6-7065478be99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-r7lXPy0O9v",
        "colab_type": "code",
        "outputId": "45987d97-ed08-4d7e-8529-b714ed1c46fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.14)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1+cu100)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.14)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.14->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: regex, pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 regex-2019.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asDkpLF00WG0",
        "colab_type": "code",
        "outputId": "992e3ef8-5715-488e-a0c2-6bff90061234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEjEPLwDzhYz",
        "colab_type": "code",
        "outputId": "7c118c9e-9917-4812-ee73-1fef3dcebecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQoFGTgG0It1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sentence and label lists\n",
        "sentences = X_train\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ZqlrKHwtQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFYJZBw91bwy",
        "colab_type": "code",
        "outputId": "e77a0306-5350-4745-beda-62648af2b99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "for tweet, bert_tokens, input_id in zip(X_train[:5],tokenized_texts[:5],input_ids[:5]):\n",
        "  print(tweet)\n",
        "  print(bert_tokens)\n",
        "  print(input_id)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pakistan ka ghra tauq he pakistan israel ko tasleem nahein kerta isko palestine kehta he occupied\n",
            "['[CLS]', 'pakistan', 'ka', 'g', '##hra', 'tau', '##q', 'he', 'pakistan', 'israel', 'ko', 'ta', '##sle', '##em', 'nah', '##ein', 'ke', '##rta', 'is', '##ko', 'palestine', 'ke', '##hta', 'he', 'occupied', '[SEP]']\n",
            "[101, 4501, 10556, 1043, 13492, 19982, 4160, 2002, 4501, 3956, 12849, 11937, 25016, 6633, 20976, 12377, 17710, 13320, 2003, 3683, 8976, 17710, 22893, 2002, 4548, 102]\n",
            "\n",
            "\n",
            "mulle ye mathura me nahi dikha tha jab mullo ne hindu ko iss liye mara ki vo lasse ki paise mag liye\n",
            "['[CLS]', 'mu', '##lle', 'ye', 'math', '##ura', 'me', 'nah', '##i', 'di', '##kha', 'tha', 'ja', '##b', 'mu', '##llo', 'ne', 'hindu', 'ko', 'iss', 'li', '##ye', 'mara', 'ki', 'vo', 'lass', '##e', 'ki', 'pa', '##ise', 'mag', 'li', '##ye', '[SEP]']\n",
            "[101, 14163, 6216, 6300, 8785, 4648, 2033, 20976, 2072, 4487, 15256, 22794, 14855, 2497, 14163, 7174, 11265, 7560, 12849, 26354, 5622, 6672, 13955, 11382, 29536, 27333, 2063, 11382, 6643, 5562, 23848, 5622, 6672, 102]\n",
            "\n",
            "\n",
            "manya pradhan mantri mahoday shriman narendra modi ji pradhanmantri banne par hardik badhai tahe\n",
            "['[CLS]', 'many', '##a', 'pr', '##ad', '##han', 'man', '##tri', 'ma', '##ho', '##day', 'shri', '##man', 'na', '##ren', '##dra', 'mod', '##i', 'ji', 'pr', '##ad', '##han', '##man', '##tri', 'ban', '##ne', 'par', 'hard', '##ik', 'bad', '##hai', 'ta', '##he', '[SEP]']\n",
            "[101, 2116, 2050, 10975, 4215, 4819, 2158, 18886, 5003, 6806, 10259, 14880, 2386, 6583, 7389, 7265, 16913, 2072, 10147, 10975, 4215, 4819, 2386, 18886, 7221, 2638, 11968, 2524, 5480, 2919, 10932, 11937, 5369, 102]\n",
            "\n",
            "\n",
            "krishna jcb full trend me chal rahi\n",
            "['[CLS]', 'krishna', 'jc', '##b', 'full', 'trend', 'me', 'cha', '##l', 'ra', '##hi', '[SEP]']\n",
            "[101, 10871, 29175, 2497, 2440, 9874, 2033, 15775, 2140, 10958, 4048, 102]\n",
            "\n",
            "\n",
            "ravishkumarblog loksabha me janta sirf modi ko vote de rahi thi na ki kisi mp or bjp ko without\n",
            "['[CLS]', 'ravi', '##sh', '##kumar', '##bl', '##og', 'lok', '##sa', '##bha', 'me', 'jan', '##ta', 'sir', '##f', 'mod', '##i', 'ko', 'vote', 'de', 'ra', '##hi', 'th', '##i', 'na', 'ki', 'ki', '##si', 'mp', 'or', 'bjp', 'ko', 'without', '[SEP]']\n",
            "[101, 16806, 4095, 18494, 16558, 8649, 13660, 3736, 22655, 2033, 5553, 2696, 2909, 2546, 16913, 2072, 12849, 3789, 2139, 10958, 4048, 16215, 2072, 6583, 11382, 11382, 5332, 6131, 2030, 24954, 12849, 2302, 102]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JbdDlMr2j7A",
        "colab_type": "code",
        "outputId": "b0461dbe-5838-4c5a-83c4-69ac0ae312c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN = max([len(bert_tokens) for bert_tokens in tokenized_texts])\n",
        "print(MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-8XLXWI2ny_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rbP2gYc1R8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17RytbQ91R3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjgfxMPn1HhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6_N2qvP2PaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbq5e2eT3fpb",
        "colab_type": "code",
        "outputId": "3aac3395-f910-4873-ca32-0c004e64b968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:32<00:00, 12509784.49B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFoNAQ5Q3jHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xAZCtdAd5oxC",
        "outputId": "429c6f17-dc6b-413b-806f-5dcbbd6f8def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXcl9o2a3x_w",
        "colab_type": "code",
        "outputId": "6e63b62e-0329-4b30-a489-f1d8a362120b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 10\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.90925086908777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [07:03<1:03:28, 423.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6118421052631579\n",
            "Train loss: 0.7690364541791974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [14:06<56:26, 423.31s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6264473684210526\n",
            "Train loss: 0.6445808046685418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [21:10<49:24, 423.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6072368421052632\n",
            "Train loss: 0.4847482921634342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [28:14<42:22, 423.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6123684210526316\n",
            "Train loss: 0.34973283315803244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [35:20<35:20, 424.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6136842105263157\n",
            "Train loss: 0.25048548599678866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [42:25<28:17, 424.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5903947368421052\n",
            "Train loss: 0.18873436112796338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [49:30<21:14, 424.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5969736842105263\n",
            "Train loss: 0.14769398915131046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [56:35<14:09, 424.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6024999999999999\n",
            "Train loss: 0.12418516706063154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [1:03:40<07:04, 424.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6005263157894737\n",
            "Train loss: 0.09802631759675036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 10/10 [1:10:44<00:00, 424.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5851315789473684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nISuv3wq33ue",
        "colab_type": "code",
        "outputId": "1b7331ca-b0d2-446c-a8ac-7cf2138601f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "torch.save(model,\"NLP3BERTSC.bin\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertForSequenceClassification. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayerNorm. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgn8MDaq39gL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=torch.load('NLP3BERTSC.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joGrWMKd39bX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(sentence):\n",
        "    #model=torch.load('Model.bin')\n",
        "    sentences = \"[CLS] \" + sentence +\" [SEP]\"\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    tokenized_texts = tokenizer.tokenize(sentences)\n",
        "#     print(tokenized_texts)\n",
        "\n",
        "    #MAX_LEN = 128\n",
        "\n",
        "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "    my_input_ids = [tokenizer.convert_tokens_to_ids(tokenized_texts)]\n",
        "    # # Pad our input tokens\n",
        "    my_input_ids = pad_sequences(my_input_ids, maxlen=MAX_LEN, dtype=\"long\",truncating=\"post\", padding=\"post\")\n",
        "    # # Create attention masks\n",
        "    my_attention_masks = []\n",
        "    # print(my_input_ids)\n",
        "    # # Create a mask of 1s for each token followed by 0s for padding\n",
        "#     print(my_input_ids)\n",
        "    for seq in my_input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        my_attention_masks.append(seq_mask)\n",
        "\n",
        "    prediction_inputs = torch.tensor(my_input_ids)\n",
        "    prediction_masks = torch.tensor(my_attention_masks)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction_inputs=prediction_inputs.to(device)\n",
        "        prediction_masks=prediction_masks.to(device)\n",
        "        logits = model(prediction_inputs.long(), attention_mask=prediction_masks.long())\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "    return np.argmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9clAFibl39ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []          \n",
        "\n",
        "for tweet in X_test:\n",
        "  y_pred.append(predict(tweet)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LABSpKYhTpFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"y_pred_BERTSC.txt\",\"w\")\n",
        "\n",
        "for i in y_pred:\n",
        "  f.write(str(i))\n",
        "  f.write(\"\\n\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJB0_sRk39Vq",
        "colab_type": "code",
        "outputId": "f17ee527-bf77-4044-f4e1-9d4be53cf57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        314      142        77\n",
            "neutral         179      299       276\n",
            "positive         66      136       380\n",
            "\n",
            "\n",
            "Accuracy:  0.5313001605136437\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.56      0.59      0.58       533\n",
            "     neutral       0.52      0.40      0.45       754\n",
            "    positive       0.52      0.65      0.58       582\n",
            "\n",
            "    accuracy                           0.53      1869\n",
            "   macro avg       0.53      0.55      0.53      1869\n",
            "weighted avg       0.53      0.53      0.53      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTMeiy1xWvF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [[314 142  77]\n",
        "#  [179 299 276]\n",
        "#  [ 66 136 380]]\n",
        "# 0.5313001605136437\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#     negative       0.56      0.59      0.58       533\n",
        "#      neutral       0.52      0.40      0.45       754\n",
        "#     positive       0.52      0.65      0.58       582\n",
        "\n",
        "#     accuracy                           0.53      1869\n",
        "#    macro avg       0.53      0.55      0.53      1869\n",
        "# weighted avg       0.53      0.53      0.53      1869\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUewRj9zMcEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}